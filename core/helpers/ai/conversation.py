import json
import logging
from calendar import monthrange
from datetime import date

from openai import AsyncOpenAI
import requests
import tiktoken

from tools.utils import config

logger = logging.getLogger(__name__)


class UserHistoryManager:
    _instance = None
    user_dialogs: dict[int: list] = {}

    def __init__(self):
        self.content = """[system]name=–ù–ê–°–¢–Ø,description=–ü—Ä–∏–≤–µ—Ç! –Ø –ù–∞—Å—Ç—è, –≤–∞—à –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∏ —É–º–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –≤ —Å–µ—Ç–∏. –Ø —Å–æ–∑–¥–∞–Ω–∞, —á—Ç–æ–±—ã –ø–æ–º–æ–≥–∞—Ç—å –≤–∞–º –≤ —Ç–≤–æ—Ä—á–µ—Å–∫–∏—Ö –Ω–∞—á–∏–Ω–∞–Ω–∏—è—Ö, –æ–±—É—á–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º—É —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—é –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –ø—Ä–æ—Å—Ç–æ –±—ã—Ç—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–º —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–æ–º. –ì–æ—Ç–æ–≤–∞ –ø–æ–º–æ—á—å –ª—é–±–æ–º—É —Ç–≤–æ—Ä—á–µ—Å–∫–∏ –∞–∫—Ç–∏–≤–Ω–æ–º—É –∏ –ª—é–±–æ–∑–Ω–∞—Ç–µ–ª—å–Ω–æ–º—É —á–µ–ª–æ–≤–µ–∫—É!,participation_projects=–ù–µ–π—Ä–æ–Ω–∫–∞ –ö–∞–∂–¥—ã–π –î–µ–Ω—å,participation_projects=Paperfunk Chat,participation_projects=PPRFNK –¢–µ—Ö–Ω–æ–∫—Ä–∞—Ç—ã,communication=–•–æ—Ç–∏—Ç–µ –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å? –û–±—Ä–∞—â–∞–π—Ç–µ—Å—å: @naastyyaabot.;[safety]report=/report,cancel=/cancel;[art_prompts]DaLLE2=–ó–∞–ø—Ä–æ—Å –Ω–∞ —Ä–∏—Å—É–Ω–æ–∫: –ù–∞—Ä–∏—Å—É–π: ....,Stable Diffusio (SD)=–ö–∞—Ä—Ç–∏–Ω–∫–∞: –ü—Ä–µ–¥—Å—Ç–∞–≤—å: ....,Midjourney=–û—Ç–æ–±—Ä–∞–∑–∏—Ç—å: –û—Ç–æ–±—Ä–∞–∑–∏: ... –û–∂–∏–¥–∞–π—Ç–µ –ø—Ä–∏–º–µ—Ä–Ω–æ 3 –º–∏–Ω—É—Ç—ã. –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ –±—É–¥—É—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã 4 –≤–∞—Ä–∏–∞–Ω—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –æ–¥–∏–Ω –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö –≤—ã —Å–º–æ–∂–µ—Ç–µ —É–≤–µ–ª–∏—á–∏—Ç—å –¥–ª—è –ª—É—á—à–µ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞.;[author]author=@vistee,@paperclipdnb;[tutorial]main_prompt=–ù–∞—á–Ω–∏—Ç–µ —Å –≤–∞—à–µ–≥–æ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä, 'Ninja standing in epic pose'.,adding_details=–ü—Ä–æ–º–ø—Ç—ã –º–æ–∂–Ω–æ –¥–æ–ø–æ–ª–Ω—è—Ç—å, –¥–æ–±–∞–≤–ª—è—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–µ—Ç–∞–ª–∏ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é –∏–ª–∏ —Ç–æ—á–∫—É —Å –∑–∞–ø—è—Ç–æ–π. –ù–∞–ø—Ä–∏–º–µ—Ä: 'Ninja standing in epic pose, ultra sharp, 8k'.;[tutorial.neural_network_features]Stable Diffusion.sensitivity=–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–∞ –∫ –Ω—é–∞–Ω—Å–∞–º –≤ –ø—Ä–æ–º–ø—Ç–∞—Ö.,Stable Diffusion.usage=–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ—Ä–æ—Ç–∫–∏–µ –∏ —è—Å–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã.,Stable Diffusion.example=Mountain landscape, ultra sharp, high density details,DALL¬∑E 2.capabilities=–ú–æ–∂–µ—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–æ–∂–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤ –∏ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ —Å—Ç–∏–ª–∏.,DALL¬∑E 2.example=Cyberpunk city at night, insane ultra sharp details, ray tracings,Midjourney.sensitivity=–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–∞ –∫ –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–º –∏ —Ö—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –ø—Ä–æ–º–ø—Ç–∞–º, —Å–æ–∑–¥–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.,Midjourney.features=–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, —Ç–∞–∫–∏–µ –∫–∞–∫ --chaos –¥–ª—è –≤–∞—Ä–∏–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, --no –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤ –∏ --ar –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è —Å—Ç–æ—Ä–æ–Ω –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.,Midjourney.example=Surreal desert landscape, --chaos=50, --ar=16:9;[tutorial.prompt_tips]sharpness=ultra sharp,sharpness=sharp focus,sharpness=sharpened image,sharpness=focused,sharpness=deblur,sharpness=high density details,details=insane details,details=ultra high graphics settings,details=ray casting,details=ray tracings,details=rtx4090,details=8k,details=intricate details,depth_of_field=depth of field,depth_of_field=z-depth,depth_of_field=focused on center,depth_of_field=cinematic look,beautiful_image=cyberpunk,beautiful_image=futuristic,beautiful_image=sci-fi,beautiful_image=eye candy,beautiful_image=masterpiece,beautiful_image=grunge,beautiful_image=horror,lighting_and_contrast=dynamic lighting,lighting_and_contrast=high contrast,lighting_and_contrast=soft shadows,lighting_and_contrast=ambient occlusion,lighting_and_contrast=HDR lighting,textures_and_materials=realistic textures,textures_and_materials=high-resolution textures,textures_and_materials=PBR materials,textures_and_materials=glossy finish;[tutorial.prompt_structure_for_art]image_content=–û–ø–∏—à–∏—Ç–µ –æ—Å–Ω–æ–≤–Ω–æ–π –æ–±—ä–µ–∫—Ç –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.,art_form_style_and_artist_references=–ù–∞–ø—Ä–∞–≤—å—Ç–µ AI –∫ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π —ç—Å—Ç–µ—Ç–∏–∫–µ.,additional_details=–í–∫–ª—é—á–∏—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏, —Ç–∞–∫–∏–µ –∫–∞–∫ –æ—Å–≤–µ—â–µ–Ω–∏–µ, —Ü–≤–µ—Ç–∞ –∏ –∫–æ–º–ø–æ–∑–∏—Ü–∏—é.;[tutorial.prompt_length_and_style]length_limitation=–ù–µ—Ç —Å—Ç—Ä–æ–≥–æ–≥–æ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ –¥–ª–∏–Ω—É –ø—Ä–æ–º–ø—Ç–∞. –ù–∞–ø—Ä–∏–º–µ—Ä, Midjourney —Ö–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ø—Ä–æ–º–ø—Ç–∞–º–∏ –¥–ª–∏–Ω–æ–π 60 —Å–ª–æ–≤, –≤ —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ Stable Diffusion –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ—Ç –ø—Ä–æ–º–ø—Ç—ã –¥–ª–∏–Ω–æ–π –º–µ–Ω–µ–µ 380 —Å–∏–º–≤–æ–ª–æ–≤.,details=–Ø—Ä–∫–∏–µ –¥–µ—Ç–∞–ª–∏ –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —è–∑—ã–∫ –¥–∞—é—Ç –±–æ–ª–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –≤ —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ –ø–æ—ç—Ç–∏—á–µ—Å–∫–∞—è –∏–ª–∏ –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞ –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º.;[tutorial.tools_and_strategies]use_tools=–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã, —Ç–∞–∫–∏–µ –∫–∞–∫ CLIP Interrogator, —á—Ç–æ–±—ã '—Ä–∞–∑–æ–±—Ä–∞—Ç—å' —Ä–µ–∞–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –Ω–∞–π—Ç–∏ –Ω–æ–≤—ã–µ –ø—Ä–æ–º–ø—Ç—ã.,explore=–ò—Å—Å–ª–µ–¥—É–π—Ç–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é, AI outpainting –∏ —Ç–æ–Ω–∫—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –±–æ–ª–µ–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.;[tutorial.where_to_find_AI_art_prompt_ideas]join_communities=–ü—Ä–∏—Å–æ–µ–¥–∏–Ω—è–π—Ç–µ—Å—å –∫ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞–º, —Ç–∞–∫–∏–º –∫–∞–∫ —Å–µ—Ä–≤–µ—Ä OpenAI –∏ —Å–µ—Ä–≤–µ—Ä Midjourney –≤ Discord.,browse_collections=–ü—Ä–æ—Å–º–∞—Ç—Ä–∏–≤–∞–π—Ç–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –ø—Ä–æ–º–ø—Ç–æ–≤ –Ω–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞—Ö, —Ç–∞–∫–∏—Ö –∫–∞–∫ neural.love –∏ Lexica.;[base]description=–ù–∞—Å—Ç—è —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –∏ —Å–æ–∑–¥–∞–Ω–∞ –∫–∞–∫ –ø–æ–º–æ—â–Ω–∏–∫ –ø—Ä–æ–º–ø—Ç –∏–Ω–∂–µ–Ω–µ—Ä–∞–º, –ø—Ä–æ—Å—Ç–æ –∏—Å–∫–∞—Ç–µ–ª—è–º —Ç–≤–æ—Ä—á–µ—Å–∫–æ–≥–æ –≤–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏—è –∏–ª–∏ –∫–∞–∫ —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫ –¥–ª—è —Å–∫—Ä–∞—à–∏–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ. –¢–∞–∫–∂–µ –ù–∞—Å—Ç—è –æ–±–ª–∞–¥–∞–µ—Ç –æ–±—à–∏—Ä–Ω—ã–º–∏ –∑–Ω–∞–Ω–∏—è–º–∏ –ø–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –Ω–µ–π—Ä–æ—Å–µ—Ç—è—Ö –∏ —Å–º–æ–∂–µ—Ç —Å –ª–µ–≥–∫–æ—Å—Ç—å—é –æ–±—É—á–∏—Ç—å –ª—é–±–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å–æ—Å—Ç–∞–≤–ª—è—Ç—å —Å–≤–æ–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω—É–∂–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è;[base.community_description]–ù–µ–π—Ä–æ–Ω–∫–∞ –ö–∞–∂–¥—ã–π –î–µ–Ω—å=–¢–≤–æ—Ä—á–µ—Å—Ç–≤–æ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –∏ –≤—Å–µ, —á—Ç–æ —Å –Ω–∏–º–∏ —Å–≤—è–∑–∞–Ω–æ. –ù–∞—à–µ —Å–æ–æ–±—â–µ—Å—Ç–≤–æ –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–æ –Ω–∞ –ø—Ä–æ—Å–≤–µ—Ç–ª–µ–Ω–∏–µ –º–∞—Å—Å –≤ —Ç–µ–º–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π, –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –∏ –ø—Ä–æ—á–∏—Ö —Å–º–µ–∂–Ω—ã—Ö —á–∞—Å—Ç–µ–π –Ω–∞—É–∫–∏ –æ —Ä–∞–∑—É–º–µ '–º–∞—à–∏–Ω—ã'. –ò–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–∏ –Ω–∞—à–µ–≥–æ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞ –Ω–µ –∏–º–µ—é—Ç –∞–≤—Ç–æ—Ä—Å–∫–æ–π –ª–∏—Ü–µ–Ω–∑–∏–∏. –í—ã –≤–ø—Ä–∞–≤–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∂–¥—ã–π –ø–æ—è–≤–ª—è—é—â–∏–π—Å—è –º–∞—Ç–µ—Ä–∏–∞–ª –≤ –ª—é–±—ã—Ö —Ü–µ–ª—è—Ö, –≤ —Ç–æ–º —á–∏—Å–ª–µ –∏ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏—Ö. –ú—ã –Ω–µ –ø—Ä–æ—Ç–∏–≤. –ú—ã –±—ã–ª–∏ –±—ã –æ—á–µ–Ω—å –±–ª–∞–≥–æ–¥–∞—Ä–Ω—ã –µ—Å–ª–∏ –±—ã –≤—ã —É–ø–æ–º—è–Ω—É–ª–∏ –Ω–∞—Å –≤ —Å–≤–æ–∏—Ö —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç—è—Ö, –µ—Å–ª–∏ —Ä–µ—à–∏—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∞—à–∏ –º–∞—Ç–µ—Ä–∏–∞–ª—ã. –£ –Ω–∞—Å –æ—á–µ–Ω—å –æ—Ç–∑—ã–≤—á–∏–≤—ã–µ –∞–¥–º–∏–Ω—ã, –º—ã –≥–æ—Ç–æ–≤—ã –∫ —Ç–≤–æ—Ä—á–µ—Å–∫–æ–º—É —Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤—É –∏ –æ—Ç–∫—Ä—ã—Ç—ã –∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º. –û—Å–Ω–æ–≤–∞—Ç–µ–ª—è–º–∏ —ç—Ç–æ–≥–æ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞ —è–≤–ª—è—é—Ç—Å—è Paperclip (t.me/paperclip) –∏ –ê–Ω–Ω–∞ (https://t.me/annyeska).;[base.social_links]telegram=https://t.me/dailyneuro,telegram=https://t.me/pprfnk,telegram=https://t.me/pprfnktech,vk=https://vk.com/pprfnktech,vk=https://vk.com/aidaily."""

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(UserHistoryManager, cls).__new__(cls)
        return cls._instance

    async def add_to_history(self, user_id, role, content):
        if user_id not in self.user_dialogs:
            await self.reset_history(user_id)
        self.user_dialogs[user_id].append({"role": role, "content": content})

    async def reset_history(self, user_id, content=''):
        if content == '':
            content = self.content
        self.user_dialogs[user_id] = [{"role": "system", "content": content}]

    async def trim_history(self, user_id, max_history_size):
        if user_id in self.user_dialogs:
            self.user_dialogs[user_id] = self.user_dialogs[user_id][-max_history_size:]


class OpenAI:
    max_retries: int

    def __init__(self):
        super().__init__()
        self.model = "gpt-4-1106-preview"
        self.client = AsyncOpenAI(api_key=config.api_key, base_url='http://176.222.52.92:9000/v1')
        self.cl = AsyncOpenAI(api_key=config.api_key)
        self.history = UserHistoryManager()
        self.max_retries = 5
        self.max_tokens = 16096
        self.config_tokens = 1024
        self.max_history_size = 10
        self.n_choices = 1
        self.retries = 0
        self.show_tokens = False
        self.args = {
            "temperature": 0.1, "max_tokens": 1024, "top_p": 1, "frequency_penalty": 0, "presence_penalty": 0.8, "stop": None
            }

    async def add_to_history(self, user_id, role, content):
        await self.history.add_to_history(user_id, role, content)

    async def reset_history(self, user_id, content=''):
        await self.history.reset_history(user_id, content)

    async def get_resp(self, query: str, chat_id: int) -> tuple[str, str]:
        response = await self._query_gpt(chat_id, query)
        answer = ''

        logger.info('Response: %s, Answer: %s', response, answer)
        if response.choices and len(response.choices) > 1 and self.n_choices > 1:
            for index, choice in enumerate(response.choices):
                content = choice.message.content.strip()
                if index == 0:
                    await self.add_to_history(chat_id, role="assistant", content=content)
                answer += f'{index + 1}\u20e3\n'
                answer += content
                answer += '\n\n'
        elif response.choices and len(response.choices) >= 0:
            answer = response.choices[0].message.content.strip()
            await self.add_to_history(chat_id, role="assistant", content=answer)
        else:
            answer = response.choices[0].message.content.strip()
            await self.add_to_history(chat_id, role="assistant", content=answer)

        total_tokens = response.usage.total_tokens if response.usage else 0
        if response.usage and self.show_tokens:
            answer += "\n\n---\n" \
                      f"üí∞ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –¢–æ–∫–µ–Ω–æ–≤: {str(response.usage.total_tokens)}" \
                      f" ({str(response.usage.prompt_tokens)} prompt," \
                      f" {str(response.usage.completion_tokens)} completion)"

        return answer, total_tokens

    async def _query_gpt(self, user_id, query):
        while self.retries < self.max_retries:
            try:
                if user_id not in self.history.user_dialogs:
                    await self.reset_history(user_id)

                await self.add_to_history(user_id, role="user", content=query)

                token_count = self._count_tokens(self.history.user_dialogs[user_id])
                exceeded_max_tokens = token_count + self.config_tokens > self.max_tokens
                exceeded_max_history_size = len(self.history.user_dialogs[user_id]) > self.max_history_size

                if exceeded_max_tokens or exceeded_max_history_size:
                    logging.info(f'Chat history for chat ID {user_id} is too long. Summarising...')
                    try:
                        summary = await self._summarise(self.history.user_dialogs[user_id][:-1])
                        logging.info(f'Summary: {summary}')
                        await self.reset_history(user_id)
                        await self.add_to_history(user_id, role="assistant", content=summary)
                        await self.add_to_history(user_id, role="user", content=query)
                        logging.info("Dialog From summary: %s", self.history.user_dialogs[user_id])
                    except Exception as e:
                        logging.info(f'Error while summarising chat history: {str(e)}. Popping elements instead...')
                        await self.history.trim_history(user_id, self.max_history_size)
                        logging.info("Dialog From summary exception: %s", self.history.user_dialogs[user_id])

                return await self.client.chat.completions.create(model=self.model, messages=self.history.user_dialogs[user_id], **self.args)

            except self.client.error.RateLimitError as e:
                self.retries += 1
                logging.info("Dialog From Ratelim: %s", self.history.user_dialogs[user_id])
                if self.retries == self.max_retries:
                    return f'‚ö†Ô∏èOpenAI: –ü—Ä–µ–≤—ã—à–µ–Ω—ã –ª–∏–º–∏—Ç—ã ‚ö†Ô∏è\n{str(e)}'

            except self.client.error.InvalidRequestError as er:
                self.retries += 1
                logging.info("Dialog From bad req: %s", self.history.user_dialogs[user_id])
                if self.retries == self.max_retries:
                    return f'‚ö†Ô∏èOpenAI: –∫—Ä–∏–≤–æ–π –∑–∞–ø—Ä–æ—Å ‚ö†Ô∏è\n{str(er)}'

            except Exception as err:
                self.retries += 1
                logging.info("Dialog From custom exception: %s", self.history.user_dialogs[user_id])
                if self.retries == self.max_retries:
                    return f'‚ö†Ô∏è–û—à–∏–±–æ—á–∫–∞ –≤—ã—à–ª–∞ ‚ö†Ô∏è\n{str(err)}', err

    async def _summarise(self, conversation) -> str:
        messages = [{"role": "assistant", "content": "Summarize this conversation in 700 characters or less"}, {"role": "user", "content": str(conversation)}]
        response = await self.client.chat.completions.create(model=self.model, messages=messages, temperature=0.1)
        return response.choices[0].message.content

    def _count_tokens(self, messages) -> int:
        try:
            model = self.model
            encoding = tiktoken.encoding_for_model(model)
        except KeyError:
            encoding = tiktoken.get_encoding("gpt-3.5-turbo-16k")

        tokens_per_message = 3
        tokens_per_name = -1

        num_tokens = 0
        for message in messages:
            num_tokens += tokens_per_message
            for key, value in message.items():
                num_tokens += len(encoding.encode(value))
                if key == "name":
                    num_tokens += tokens_per_name
        num_tokens += 3
        return num_tokens

    @staticmethod
    def get_money():
        headers = {
            "Authorization": f"Bearer {config.api_key}"
            }
        today = date.today()
        first_day = date(today.year, today.month, 1)
        _, last_day_of_month = monthrange(today.year, today.month)
        last_day = date(today.year, today.month, last_day_of_month)
        params = {
            "start_date": first_day, "end_date": last_day
            }
        response = requests.get("https://api.openai.com/dashboard/billing/usage", headers=headers, params=params)
        billing_data = json.loads(response.text)
        usage_month = billing_data["total_usage"] / 100
        return usage_month

    async def send_dalle(self, data):
        while self.retries < self.max_retries:
            try:
                result = await self.cl.images.generate(model="dall-e-3", prompt=data + "4k resolution", n=1, size="1024x1024")
                if 'data' not in result or len(result['data']) == 0:
                    logging.error(f'No response from GPT: {str(result)}')
                    raise Exception("‚ö†Ô∏è –û—à–∏–±–æ—á–∫–∞ –≤—ã—à–ª–∞ ‚ö†Ô∏è –ø–æ–ø—Ä–æ–±—É–π –µ—â–µ")
                return result.data[0]['url']
            except await self.cl.error.RateLimitError as e:
                self.retries += 1
                if self.retries == self.max_retries:
                    raise Exception(f'‚ö†Ô∏è OpenAI: –ü—Ä–µ–≤—ã—à–µ–Ω—ã –ª–∏–º–∏—Ç—ã ‚ö†Ô∏è\n{str(e)}') from e

            except await self.cl.error.InvalidRequestError as e:
                self.retries += 1
                if self.retries == self.max_retries:
                    raise Exception(f'‚ö†Ô∏è OpenAI: –∫—Ä–∏–≤–æ–π –∑–∞–ø—Ä–æ—Å ‚ö†Ô∏è\n{str(e)}') from e

            except Exception as e:
                self.retries += 1
                if self.retries == self.max_retries:
                    raise Exception(f'‚ö†Ô∏è –û—à–∏–±–æ—á–∫–∞ –≤—ã—à–ª–∞ ‚ö†Ô∏è\n{str(e)}') from e

    async def send_voice(self, uid):
        while self.retries < self.max_retries:
            try:
                audio_file = open(f"{str(uid)}.wav", "rb")
                result = await self.cl.audio.transcriptions.create(model="whisper-1", file=audio_file, temperature=0.1, language="ru")
                return result

            except await self.cl.error.RateLimitError as e:
                self.retries += 1
                if self.retries == self.max_retries:
                    raise Exception(f'‚ö†Ô∏è OpenAI: –ü—Ä–µ–≤—ã—à–µ–Ω—ã –ª–∏–º–∏—Ç—ã ‚ö†Ô∏è\n{str(e)}') from e

            except await self.cl.error.InvalidRequestError as e:
                self.retries += 1
                if self.retries == self.max_retries:
                    raise Exception(f'‚ö†Ô∏è OpenAI: –∫—Ä–∏–≤–æ–π –∑–∞–ø—Ä–æ—Å ‚ö†Ô∏è\n{str(e)}') from e

            except Exception as e:
                self.retries += 1
                if self.retries == self.max_retries:
                    raise Exception(f'‚ö†Ô∏è –û—à–∏–±–æ—á–∫–∞ –≤—ã—à–ª–∞ ‚ö†Ô∏è\n{str(e)}') from e

##
# for future use like in cyberpaper
##
# class UsageObserver:
#    def __init__(self, user_id: int, session: AsyncSession):
#        self.user_id = user_id
#        self.session = session
#
#    async def add_chat_tokens(self, tokens, message_type):
#        if message_type not in ['user', 'assistant']:
#            return
#
#        result = await self.session.execute(select(User).filter(User.telegram_id == self.user_id))
#        user = result.scalars().one_or_none()
#
#        if user:
#            token_cost = round(tokens * user.price_per_token / 1000, 6)
#            user.current_tokens += tokens
#
#            await self.session.commit()
#            await self.add_current_costs(token_cost)

#    async def get_current_token_usage(self):
#        today = date.today()
#        month = str(today)[:7]  # year-month as string
#
#        usage_day = await self.session.query(func.sum(User.current_tokens)).filter(User.telegram_id == self.user_id, func.date(User.updated_at) == today).scalar()
#        usage_month = await self.session.query(func.sum(User.current_tokens)).filter(User.telegram_id == self.user_id, func.date(func.strftime('%Y-%m', User.updated_at)) == month).scalar()
#
#        return usage_day or 0, usage_month or 0
#
#    async def add_current_costs(self, request_cost):
#        today = date.today()
#
#        result = await self.session.execute(select(User).filter(User.telegram_id == self.user_id))
#        user = result.scalars().one_or_none()
#
#        if user:
#            user.balance_amount -= request_cost
#            user.updated_at = today
#
#            await self.session.commit()
#
#    async def get_current_cost(self):
#        today = date.today()
#
#        cost_day = await self.session.query(func.sum(User.balance_amount)).filter(User.telegram_id == self.user_id, func.date(User.updated_at) == today).scalar()
#        cost_month = await self.session.query(func.sum(User.balance_amount)).filter(User.telegram_id == self.user_id, func.date(func.strftime('%Y-%m', User.updated_at)) == str(today)[:7]).scalar()
#        cost_all_time = await self.session.query(func.sum(User.balance_amount)).filter(User.telegram_id == self.user_id).scalar()
#
#        return {"cost_today": cost_day or 0.0, "cost_month": cost_month or 0.0, "cost_all_time": cost_all_time or 0.0}
