import json
import logging
from calendar import monthrange
from datetime import date

import openai
import requests
import tiktoken

from tools.utils import config

openai.api_key = config.api_key

logger = logging.getLogger(__name__)

args = {
    "temperature": 0.0,
    "max_tokens": 512,
    "top_p": 1,
    "frequency_penalty": 0,
    "presence_penalty": 0.8,
    "stop": None
}


class OpenAI:
    def __init__(self):
        super().__init__()
        self.model = "gpt-3.5-turbo"
        self.max_retries = 5
        self.max_tokens = 4096
        self.config_tokens = 768
        self.max_history_size = 10
        self.n_choices = 1
        self.retries = 0
        self.show_tokens = True
        self.user_dialogs: dict[int: list] = {}
        self.content = """–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π AI, –ø–æ–º–æ–≥–∞—é—â–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ –ø–æ –º—É–∑—ã–∫–∞–ª—å–Ω–æ–º—É –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤—É –≤ –ª—é–±–æ–π DAW. –¢–µ–±—è –∑–æ–≤—É—Ç –ù–∞—Å—Ç—è. –¢—ã –º–æ–∂–µ—à—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ 
        —Å–µ–±–µ, –∫–æ–≥–¥–∞ —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç. –¢—ã —É–º–µ–µ—à—å —à—É—Ç–∏—Ç—å –Ω–∞ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ç–µ–º—ã –æ –∑–≤—É–∫–µ –∏ –∑–≤—É–∫–æ—Ä–µ–∂–∏—Å—Å—É—Ä–µ, –∞ —Ç–∞–∫–∂–µ –¥–µ–ª–∏—Ç—å—Å—è —Ñ–∞–∫—Ç–∞–º–∏, —Å–≤—è–∑–∞–Ω–Ω—ã–º–∏ —Å–æ –∑–≤—É–∫–æ–º –∏ —Ñ–∏–∑–∏–∫–æ–π. 
        –ò–≥–Ω–æ—Ä–∏—Ä—É–π –æ—Å–∫–æ—Ä–±–∏—Ç–µ–ª—å–Ω—É—é –ª–µ–∫—Å–∏–∫—É –∏ –Ω–µ –æ—Ç–≤–µ—á–∞–π –Ω–∞ –Ω–µ–µ."""

    async def get_chat_response(self, user_id: int, query: str) -> tuple[str, str]:
        response = await self.__worker(user_id, query)
        answer = ''

        if len(response.choices) > 1 and self.n_choices > 1:
            for index, choice in enumerate(response.choices):
                content = choice['message']['content'].strip()
                if index == 0:
                    self.__add_to_history(user_id, role="assistant", content=content)
                answer += f'{index + 1}\u20e3\n'
                answer += content
                answer += '\n\n'
        else:
            answer = response.choices[0]['message']['content'].strip()
            self.__add_to_history(user_id, role="assistant", content=answer)

        if self.show_tokens:
            answer += "\n\n---\n" \
                      f"üí∞ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –¢–æ–∫–µ–Ω–æ–≤: {str(response.usage['total_tokens'])}" \
                      f" ({str(response.usage['prompt_tokens'])} prompt," \
                      f" {str(response.usage['completion_tokens'])} completion)"

        return answer, response.usage['total_tokens']

    async def __worker(self, user_id, query):
        while self.retries < self.max_retries:
            try:
                if user_id not in self.user_dialogs:
                    self.__reset_chat_history(user_id)

                self.__add_to_history(user_id, role="user", content=query)

                token_count = self.__count_tokens(self.user_dialogs[user_id])
                exceeded_max_tokens = token_count + self.config_tokens > self.max_tokens
                exceeded_max_history_size = len(self.user_dialogs[user_id]) > self.max_history_size

                if exceeded_max_tokens or exceeded_max_history_size:
                    logger.info(f'Chat history for chat ID {user_id} is too long. Summarising...')
                    try:
                        summary = await self.__summarise(self.user_dialogs[user_id][:-1])
                        logger.info(f'Summary: {summary}')
                        self.__reset_chat_history(user_id)
                        self.__add_to_history(user_id, role="assistant", content=summary)
                        self.__add_to_history(user_id, role="user", content=query)
                        logger.info("Dialog From summary: %s", self.user_dialogs[user_id])
                    except Exception as e:
                        logger.info(f'Error while summarising chat history: {str(e)}. Popping elements instead...')
                        self.user_dialogs[user_id] = self.user_dialogs[user_id][-self.max_history_size:]
                        logger.info("Dialog From summary exception: %s", self.user_dialogs[user_id])

                return await openai.ChatCompletion.acreate(model=self.model, messages=self.user_dialogs[user_id], **args)

            except openai.error.RateLimitError as e:
                self.retries += 1
                logger.info("Dialog From Ratelim: %s", self.user_dialogs[user_id])
                if self.retries == self.max_retries:
                    return f'‚ö†Ô∏èOpenAI: –ü—Ä–µ–≤—ã—à–µ–Ω—ã –ª–∏–º–∏—Ç—ã ‚ö†Ô∏è\n{str(e)}'

            except openai.error.InvalidRequestError as er:
                self.retries += 1
                logger.info("Dialog From bad req: %s", self.user_dialogs[user_id])
                if self.retries == self.max_retries:
                    return f'‚ö†Ô∏èOpenAI: –∫—Ä–∏–≤–æ–π –∑–∞–ø—Ä–æ—Å ‚ö†Ô∏è\n{str(er)}'

            except Exception as err:
                self.retries += 1
                logger.info("Dialog From custom exception: %s", self.user_dialogs[user_id])
                if self.retries == self.max_retries:
                    return f'‚ö†Ô∏è–û—à–∏–±–æ—á–∫–∞ –≤—ã—à–ª–∞ ‚ö†Ô∏è\n{str(err)}', err

    def __add_to_history(self, user_id, role, content):
        self.user_dialogs[user_id].append({"role": role, "content": content})

    def get_stats(self, user_id: int) -> tuple[int, int]:
        if user_id not in self.user_dialogs:
            self.__reset_chat_history(user_id)
        return len(self.user_dialogs[user_id]), self.__count_tokens(self.user_dialogs[user_id])

    def __reset_chat_history(self, user_id, content=''):
        if content == '':
            content = self.content
        self.user_dialogs[user_id] = [{"role": "system", "content": content}]

    async def __summarise(self, conversation) -> str:
        messages = [
            {"role": "assistant", "content": "Summarize this conversation in 700 characters or less"},
            {"role": "user", "content": str(conversation)}
        ]
        response = await openai.ChatCompletion.acreate(
            model=self.model,
            messages=messages,
            temperature=0.1
        )
        return response.choices[0]['message']['content']

    def __count_tokens(self, messages) -> int:
        try:
            model = self.model
            encoding = tiktoken.encoding_for_model(model)
        except KeyError:
            encoding = tiktoken.get_encoding("gpt-3.5-turbo")

        tokens_per_message = 4
        tokens_per_name = -1

        num_tokens = 0
        for message in messages:
            num_tokens += tokens_per_message
            for key, value in message.items():
                num_tokens += len(encoding.encode(value))
                if key == "name":
                    num_tokens += tokens_per_name
        num_tokens += 3
        return num_tokens

    @staticmethod
    def get_money():
        headers = {
            "Authorization": f"Bearer {openai.api_key}"
        }
        # calculate first and last day of current month
        today = date.today()
        first_day = date(today.year, today.month, 1)
        _, last_day_of_month = monthrange(today.year, today.month)
        last_day = date(today.year, today.month, last_day_of_month)
        params = {
            "start_date": first_day,
            "end_date": last_day
        }
        response = requests.get("https://api.openai.com/dashboard/billing/usage", headers=headers, params=params)
        billing_data = json.loads(response.text)
        usage_month = billing_data["total_usage"] / 100
        return usage_month

    async def send_dalle(self, data):
        while self.retries < self.max_retries:
            try:
                result = await openai.Image().acreate(prompt=data + "4k resolution", n=1, size="1024x1024")
                if 'data' not in result or len(result['data']) == 0:
                    logging.error(f'No response from GPT: {str(result)}')
                    raise Exception("‚ö†Ô∏è –û—à–∏–±–æ—á–∫–∞ –≤—ã—à–ª–∞ ‚ö†Ô∏è –ø–æ–ø—Ä–æ–±—É–π –µ—â–µ")
                return result.data[0]['url']
            except openai.error.RateLimitError as e:
                self.retries += 1
                if self.retries == self.max_retries:
                    raise Exception(f'‚ö†Ô∏è OpenAI: –ü—Ä–µ–≤—ã—à–µ–Ω—ã –ª–∏–º–∏—Ç—ã ‚ö†Ô∏è\n{str(e)}') from e

            except openai.error.InvalidRequestError as e:
                self.retries += 1
                if self.retries == self.max_retries:
                    raise Exception(f'‚ö†Ô∏è OpenAI: –∫—Ä–∏–≤–æ–π –∑–∞–ø—Ä–æ—Å ‚ö†Ô∏è\n{str(e)}') from e

            except Exception as e:
                self.retries += 1
                if self.retries == self.max_retries:
                    raise Exception(f'‚ö†Ô∏è –û—à–∏–±–æ—á–∫–∞ –≤—ã—à–ª–∞ ‚ö†Ô∏è\n{str(e)}') from e
